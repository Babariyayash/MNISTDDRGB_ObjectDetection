{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT-njnYCZtkE",
        "outputId": "60b77828-7dff-4305-9010-798061e2e959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "gHz3obyTZ6He"
      },
      "outputs": [],
      "source": [
        "class DarkResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(DarkResidualBlock, self).__init__()\n",
        "        out_channels = int(in_channels/2)\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "                      nn.Conv2d(in_channels, out_channels, kernel_size=1,stride = 1, padding=0, bias=False),\n",
        "                      nn.BatchNorm2d(out_channels),\n",
        "                      nn.LeakyReLU())\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "                      nn.Conv2d(out_channels, in_channels, kernel_size=3,stride = 1, padding=1, bias=False),\n",
        "                      nn.BatchNorm2d(in_channels),\n",
        "                      nn.LeakyReLU())\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out += residual\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "B-5qW9UKZ9_m"
      },
      "outputs": [],
      "source": [
        "class MNISTDDRGBDarknet53(nn.Module):\n",
        "    def __init__(self, block, num_classes):\n",
        "        super(MNISTDDRGBDarknet53, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "                      nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                      nn.BatchNorm2d(32),\n",
        "                      nn.LeakyReLU())\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "                      nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "                      nn.BatchNorm2d(64),\n",
        "                      nn.LeakyReLU())\n",
        "\n",
        "        self.residual_block1 = self.make_layer(block, in_channels=64, num_blocks=1)\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "                      nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "                      nn.BatchNorm2d(128),\n",
        "                      nn.LeakyReLU())\n",
        "\n",
        "        self.residual_block2 = self.make_layer(block, in_channels=128, num_blocks=2)\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "                      nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "                      nn.BatchNorm2d(256),\n",
        "                      nn.LeakyReLU())\n",
        "\n",
        "        self.residual_block3 = self.make_layer(block, in_channels=256, num_blocks=8)\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "                      nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "                      nn.BatchNorm2d(512),\n",
        "                      nn.LeakyReLU())\n",
        "\n",
        "        self.residual_block4 = self.make_layer(block, in_channels=512, num_blocks=8)\n",
        "\n",
        "        self.conv6 = nn.Sequential(\n",
        "                      nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "                      nn.BatchNorm2d(1024),\n",
        "                      nn.LeakyReLU())\n",
        "\n",
        "        self.residual_block5 = self.make_layer(block, in_channels=1024, num_blocks=4)\n",
        "\n",
        "\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(1024, self.num_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.residual_block1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.residual_block2(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.residual_block3(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.residual_block4(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.residual_block5(x)\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(-1, 1024)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def make_layer(self, block, in_channels, num_blocks):\n",
        "        layers = []\n",
        "        for i in range(0, num_blocks):\n",
        "            layers.append(block(in_channels))\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "rWyKlXrJaCnK"
      },
      "outputs": [],
      "source": [
        "def MNISTDDDark(num_classes):\n",
        "    return MNISTDDRGBDarknet53(DarkResidualBlock,num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "_bRPrSF9aF3g"
      },
      "outputs": [],
      "source": [
        "class CustomModel:\n",
        "    def __init__(self,pth):\n",
        "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "        print(self.device)\n",
        "        model = MNISTDDDark(28)\n",
        "        model.load_state_dict(torch.load(pth, map_location=self.device))\n",
        "        self.Darknet53 = model.to(self.device)\n",
        "    def predict(self,image):\n",
        "        self.Darknet53.eval()\n",
        "        gray = image.reshape(64, 64, 3)\n",
        "        with torch.no_grad():\n",
        "            gray_tensor = torch.from_numpy(gray.astype(np.float32) / 255.).permute(2, 0, 1).unsqueeze(0).to(self.device)\n",
        "            oh = self.Darknet53(gray_tensor)\n",
        "            oh_class = oh[:, :20].contiguous().view(-1, 10)\n",
        "            oh_box = oh[:, 20:]\n",
        "\n",
        "            # Sort the tensor by ascending order\n",
        "            pred_class = oh_class.argmax(1).cpu().numpy()\n",
        "            pred_box = oh_box.long().cpu().numpy()[0].reshape(2,4)\n",
        "            # pred_seg = oh_seg.argmax(1).cpu().numpy().reshape(64, 64)  # Update this line for the correct shape\n",
        "\n",
        "        return pred_class,pred_box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BvDE5kTiEd4s"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "FF0wZrXLaMYK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def detect_and_segment(images):\n",
        "    \"\"\"\n",
        "\n",
        "    :param np.ndarray images: N x 12288 array containing N 64x64x3 images flattened into vectors\n",
        "    :return: np.ndarray, np.ndarray\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    N = images.shape[0]\n",
        "\n",
        "    # pred_class: Your predicted labels for the 2 digits, shape [N, 2]\n",
        "    pred_class = np.empty((N, 2), dtype=np.int32)\n",
        "    # pred_bboxes: Your predicted bboxes for 2 digits, shape [N, 2, 4]\n",
        "    pred_bboxes = np.empty((N, 2, 4), dtype=np.float64)\n",
        "    # pred_seg: Your predicted segmentation for the image, shape [N, 4096]\n",
        "    pred_seg = np.empty((N, 4096), dtype=np.int32)\n",
        "\n",
        "    print(os.listdir())\n",
        "    # add your code here to fill in pred_class and pred_bboxes\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "    # Image Classification and bboxes\n",
        "    images_1 = images\n",
        "    model = CustomModel(\"/content/gdrive/MyDrive/visual_recognition_data/checkpoint_32.pth\")\n",
        "\n",
        "    # Image Segmentation\n",
        "    images = images.reshape([images.shape[0], 64, 64, 3])\n",
        "    images = np.transpose(images, (0, 3, 1, 2))\n",
        "    model2 = UNet(3,11).to(device)\n",
        "    model2.load_state_dict(torch.load(\"/content/gdrive/My Drive/visual_recognition_data/checkpoint_15.pth\", map_location=device))\n",
        "    model2 = model2.to(device)\n",
        "\n",
        "    for i in range(N):\n",
        "        label,box=model.predict(images_1[i,:])\n",
        "\n",
        "        box[0,2] = box[0,0] + 28\n",
        "        box[0,3] = box[0,1] + 28\n",
        "        box[1,2] = box[1,0] + 28\n",
        "        box[1,3] = box[1,1] + 28\n",
        "        pred_class[i,:]=label\n",
        "        pred_bboxes[i,:]=box\n",
        "\n",
        "        image_seg = torch.as_tensor(images[i]).float()\n",
        "        logit = model2(image_seg.to(device).view(-1,3,64,64))\n",
        "        pred = logit.argmax(1).view(-1).long().cpu().numpy()\n",
        "        pred_seg[i,:] = pred\n",
        "\n",
        "\n",
        "    return pred_class, pred_bboxes, pred_seg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RFx1fViZcZAG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\"\"\"BGR values for different colors\"\"\"\n",
        "col_bgr = {\n",
        "    'snow': (250, 250, 255),\n",
        "    'snow_2': (233, 233, 238),\n",
        "    'snow_3': (201, 201, 205),\n",
        "    'snow_4': (137, 137, 139),\n",
        "    'ghost_white': (255, 248, 248),\n",
        "    'white_smoke': (245, 245, 245),\n",
        "    'gainsboro': (220, 220, 220),\n",
        "    'floral_white': (240, 250, 255),\n",
        "    'old_lace': (230, 245, 253),\n",
        "    'linen': (230, 240, 240),\n",
        "    'antique_white': (215, 235, 250),\n",
        "    'antique_white_2': (204, 223, 238),\n",
        "    'antique_white_3': (176, 192, 205),\n",
        "    'antique_white_4': (120, 131, 139),\n",
        "    'papaya_whip': (213, 239, 255),\n",
        "    'blanched_almond': (205, 235, 255),\n",
        "    'bisque': (196, 228, 255),\n",
        "    'bisque_2': (183, 213, 238),\n",
        "    'bisque_3': (158, 183, 205),\n",
        "    'bisque_4': (107, 125, 139),\n",
        "    'peach_puff': (185, 218, 255),\n",
        "    'peach_puff_2': (173, 203, 238),\n",
        "    'peach_puff_3': (149, 175, 205),\n",
        "    'peach_puff_4': (101, 119, 139),\n",
        "    'navajo_white': (173, 222, 255),\n",
        "    'moccasin': (181, 228, 255),\n",
        "    'cornsilk': (220, 248, 255),\n",
        "    'cornsilk_2': (205, 232, 238),\n",
        "    'cornsilk_3': (177, 200, 205),\n",
        "    'cornsilk_4': (120, 136, 139),\n",
        "    'ivory': (240, 255, 255),\n",
        "    'ivory_2': (224, 238, 238),\n",
        "    'ivory_3': (193, 205, 205),\n",
        "    'ivory_4': (131, 139, 139),\n",
        "    'lemon_chiffon': (205, 250, 255),\n",
        "    'seashell': (238, 245, 255),\n",
        "    'seashell_2': (222, 229, 238),\n",
        "    'seashell_3': (191, 197, 205),\n",
        "    'seashell_4': (130, 134, 139),\n",
        "    'honeydew': (240, 255, 240),\n",
        "    'honeydew_2': (224, 238, 244),\n",
        "    'honeydew_3': (193, 205, 193),\n",
        "    'honeydew_4': (131, 139, 131),\n",
        "    'mint_cream': (250, 255, 245),\n",
        "    'azure': (255, 255, 240),\n",
        "    'alice_blue': (255, 248, 240),\n",
        "    'lavender': (250, 230, 230),\n",
        "    'lavender_blush': (245, 240, 255),\n",
        "    'misty_rose': (225, 228, 255),\n",
        "    'white': (255, 255, 255),\n",
        "    'black': (0, 0, 0),\n",
        "    'dark_slate_gray': (79, 79, 49),\n",
        "    'dim_gray': (105, 105, 105),\n",
        "    'slate_gray': (144, 138, 112),\n",
        "    'light_slate_gray': (153, 136, 119),\n",
        "    'gray': (190, 190, 190),\n",
        "    'light_gray': (211, 211, 211),\n",
        "    'midnight_blue': (112, 25, 25),\n",
        "    'navy': (128, 0, 0),\n",
        "    'cornflower_blue': (237, 149, 100),\n",
        "    'dark_slate_blue': (139, 61, 72),\n",
        "    'slate_blue': (205, 90, 106),\n",
        "    'medium_slate_blue': (238, 104, 123),\n",
        "    'light_slate_blue': (255, 112, 132),\n",
        "    'medium_blue': (205, 0, 0),\n",
        "    'royal_blue': (225, 105, 65),\n",
        "    'blue': (255, 0, 0),\n",
        "    'dodger_blue': (255, 144, 30),\n",
        "    'deep_sky_blue': (255, 191, 0),\n",
        "    'sky_blue': (250, 206, 135),\n",
        "    'light_sky_blue': (250, 206, 135),\n",
        "    'steel_blue': (180, 130, 70),\n",
        "    'light_steel_blue': (222, 196, 176),\n",
        "    'light_blue': (230, 216, 173),\n",
        "    'powder_blue': (230, 224, 176),\n",
        "    'pale_turquoise': (238, 238, 175),\n",
        "    'dark_turquoise': (209, 206, 0),\n",
        "    'medium_turquoise': (204, 209, 72),\n",
        "    'turquoise': (208, 224, 64),\n",
        "    'cyan': (255, 255, 0),\n",
        "    'light_cyan': (255, 255, 224),\n",
        "    'cadet_blue': (160, 158, 95),\n",
        "    'medium_aquamarine': (170, 205, 102),\n",
        "    'aquamarine': (212, 255, 127),\n",
        "    'dark_green': (0, 100, 0),\n",
        "    'dark_olive_green': (47, 107, 85),\n",
        "    'dark_sea_green': (143, 188, 143),\n",
        "    'sea_green': (87, 139, 46),\n",
        "    'medium_sea_green': (113, 179, 60),\n",
        "    'light_sea_green': (170, 178, 32),\n",
        "    'pale_green': (152, 251, 152),\n",
        "    'spring_green': (127, 255, 0),\n",
        "    'lawn_green': (0, 252, 124),\n",
        "    'chartreuse': (0, 255, 127),\n",
        "    'medium_spring_green': (154, 250, 0),\n",
        "    'green_yellow': (47, 255, 173),\n",
        "    'lime_green': (50, 205, 50),\n",
        "    'yellow_green': (50, 205, 154),\n",
        "    'forest_green': (34, 139, 34),\n",
        "    'olive_drab': (35, 142, 107),\n",
        "    'dark_khaki': (107, 183, 189),\n",
        "    'khaki': (140, 230, 240),\n",
        "    'pale_goldenrod': (170, 232, 238),\n",
        "    'light_goldenrod_yellow': (210, 250, 250),\n",
        "    'light_yellow': (224, 255, 255),\n",
        "    'yellow': (0, 255, 255),\n",
        "    'gold': (0, 215, 255),\n",
        "    'light_goldenrod': (130, 221, 238),\n",
        "    'goldenrod': (32, 165, 218),\n",
        "    'dark_goldenrod': (11, 134, 184),\n",
        "    'rosy_brown': (143, 143, 188),\n",
        "    'indian_red': (92, 92, 205),\n",
        "    'saddle_brown': (19, 69, 139),\n",
        "    'sienna': (45, 82, 160),\n",
        "    'peru': (63, 133, 205),\n",
        "    'burlywood': (135, 184, 222),\n",
        "    'beige': (220, 245, 245),\n",
        "    'wheat': (179, 222, 245),\n",
        "    'sandy_brown': (96, 164, 244),\n",
        "    'tan': (140, 180, 210),\n",
        "    'chocolate': (30, 105, 210),\n",
        "    'firebrick': (34, 34, 178),\n",
        "    'brown': (42, 42, 165),\n",
        "    'dark_salmon': (122, 150, 233),\n",
        "    'salmon': (114, 128, 250),\n",
        "    'light_salmon': (122, 160, 255),\n",
        "    'orange': (0, 165, 255),\n",
        "    'dark_orange': (0, 140, 255),\n",
        "    'coral': (80, 127, 255),\n",
        "    'light_coral': (128, 128, 240),\n",
        "    'tomato': (71, 99, 255),\n",
        "    'orange_red': (0, 69, 255),\n",
        "    'red': (0, 0, 255),\n",
        "    'hot_pink': (180, 105, 255),\n",
        "    'deep_pink': (147, 20, 255),\n",
        "    'pink': (203, 192, 255),\n",
        "    'light_pink': (193, 182, 255),\n",
        "    'pale_violet_red': (147, 112, 219),\n",
        "    'maroon': (96, 48, 176),\n",
        "    'medium_violet_red': (133, 21, 199),\n",
        "    'violet_red': (144, 32, 208),\n",
        "    'violet': (238, 130, 238),\n",
        "    'plum': (221, 160, 221),\n",
        "    'orchid': (214, 112, 218),\n",
        "    'medium_orchid': (211, 85, 186),\n",
        "    'dark_orchid': (204, 50, 153),\n",
        "    'dark_violet': (211, 0, 148),\n",
        "    'blue_violet': (226, 43, 138),\n",
        "    'purple': (240, 32, 160),\n",
        "    'medium_purple': (219, 112, 147),\n",
        "    'thistle': (216, 191, 216),\n",
        "    'green': (0, 255, 0),\n",
        "    'magenta': (255, 0, 255)\n",
        "}\n",
        "\n",
        "\n",
        "class CVText:\n",
        "    def __init__(self, color='white', bkg_color='black', location=0, font=3,\n",
        "                 size=0.8, thickness=1, line_type=2, offset=(5, 25)):\n",
        "        self.color = color\n",
        "        self.bkg_color = bkg_color\n",
        "        self.location = location\n",
        "        self.font = font\n",
        "        self.size = size\n",
        "        self.thickness = thickness\n",
        "        self.line_type = line_type\n",
        "        self.offset = offset\n",
        "\n",
        "        self.help = {\n",
        "            'font': 'Available fonts: '\n",
        "                    '0: cv2.FONT_HERSHEY_SIMPLEX, '\n",
        "                    '1: cv2.FONT_HERSHEY_PLAIN, '\n",
        "                    '2: cv2.FONT_HERSHEY_DUPLEX, '\n",
        "                    '3: cv2.FONT_HERSHEY_COMPLEX, '\n",
        "                    '4: cv2.FONT_HERSHEY_TRIPLEX, '\n",
        "                    '5: cv2.FONT_HERSHEY_COMPLEX_SMALL, '\n",
        "                    '6: cv2.FONT_HERSHEY_SCRIPT_SIMPLEX ,'\n",
        "                    '7: cv2.FONT_HERSHEY_SCRIPT_COMPLEX; ',\n",
        "            'location': '0: top left, 1: top right, 2: bottom right, 3: bottom left; ',\n",
        "            'bkg_color': 'should be empty for no background',\n",
        "        }\n",
        "\n",
        "\n",
        "class CVConstants:\n",
        "    interp_types = {\n",
        "        0: cv2.INTER_NEAREST,\n",
        "        1: cv2.INTER_LINEAR,\n",
        "        2: cv2.INTER_AREA,\n",
        "        3: cv2.INTER_CUBIC,\n",
        "        4: cv2.INTER_LANCZOS4\n",
        "    }\n",
        "    fonts = {\n",
        "        0: cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        1: cv2.FONT_HERSHEY_PLAIN,\n",
        "        2: cv2.FONT_HERSHEY_DUPLEX,\n",
        "        3: cv2.FONT_HERSHEY_COMPLEX,\n",
        "        4: cv2.FONT_HERSHEY_TRIPLEX,\n",
        "        5: cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "        6: cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
        "        7: cv2.FONT_HERSHEY_SCRIPT_COMPLEX\n",
        "    }\n",
        "    line_types = {\n",
        "        0: cv2.LINE_4,\n",
        "        1: cv2.LINE_8,\n",
        "        2: cv2.LINE_AA,\n",
        "    }\n",
        "\n",
        "\n",
        "def stack_images(img_list, grid_size=None, stack_order=0, borderless=1,\n",
        "                 preserve_order=0, return_idx=0,\n",
        "                 only_height=0, placement_type=0):\n",
        "    n_images = len(img_list)\n",
        "\n",
        "    if grid_size is None or not grid_size:\n",
        "        n_cols = n_rows = int(np.ceil(np.sqrt(n_images)))\n",
        "    else:\n",
        "        n_rows, n_cols = grid_size\n",
        "\n",
        "        if n_rows < 0:\n",
        "            n_rows = int(np.ceil(n_images / n_cols))\n",
        "        elif n_cols < 0:\n",
        "            n_cols = int(np.ceil(n_images / n_rows))\n",
        "\n",
        "    target_ar = 1920.0 / 1080.0\n",
        "    if n_cols <= n_rows:\n",
        "        target_ar /= 2.0\n",
        "    shape_img_id = 0\n",
        "    min_ar_diff = np.inf\n",
        "    img_heights = np.zeros((n_images,), dtype=np.int32)\n",
        "    for _img_id in range(n_images):\n",
        "        height, width = img_list[_img_id].shape[:2]\n",
        "        img_heights[_img_id] = height\n",
        "        img_ar = float(n_cols * width) / float(n_rows * height)\n",
        "        ar_diff = abs(img_ar - target_ar)\n",
        "        if ar_diff < min_ar_diff:\n",
        "            min_ar_diff = ar_diff\n",
        "            shape_img_id = _img_id\n",
        "\n",
        "    img_heights_sort_idx = np.argsort(-img_heights)\n",
        "    row_start_idx = img_heights_sort_idx[:n_rows]\n",
        "    img_idx = img_heights_sort_idx[n_rows:]\n",
        "    img_size = img_list[shape_img_id].shape\n",
        "    height, width = img_size[:2]\n",
        "\n",
        "    if only_height:\n",
        "        width = 0\n",
        "\n",
        "    stacked_img = None\n",
        "    list_ended = False\n",
        "    img_idx_id = 0\n",
        "    inner_axis = 1 - stack_order\n",
        "    stack_idx = []\n",
        "    stack_locations = []\n",
        "    start_row = 0\n",
        "    # curr_ann = ''\n",
        "    for row_id in range(n_rows):\n",
        "        start_id = n_cols * row_id\n",
        "        curr_row = None\n",
        "        start_col = 0\n",
        "        for col_id in range(n_cols):\n",
        "            img_id = start_id + col_id\n",
        "            if img_id >= n_images:\n",
        "                curr_img = np.zeros(img_size, dtype=np.uint8)\n",
        "                list_ended = True\n",
        "            else:\n",
        "                if preserve_order:\n",
        "                    _curr_img_id = img_id\n",
        "                elif col_id == 0:\n",
        "                    _curr_img_id = row_start_idx[row_id]\n",
        "                else:\n",
        "                    _curr_img_id = img_idx[img_idx_id]\n",
        "                    img_idx_id += 1\n",
        "\n",
        "                curr_img = img_list[_curr_img_id]\n",
        "                stack_idx.append(_curr_img_id)\n",
        "                if not borderless:\n",
        "                    curr_img = resize_ar(curr_img, width, height)\n",
        "                if img_id == n_images - 1:\n",
        "                    list_ended = True\n",
        "            if curr_row is None:\n",
        "                curr_row = curr_img\n",
        "            else:\n",
        "                if borderless:\n",
        "                    if curr_row.shape[0] < curr_img.shape[0]:\n",
        "                        curr_row = resize_ar(curr_row, 0, curr_img.shape[0])\n",
        "                    elif curr_img.shape[0] < curr_row.shape[0]:\n",
        "                        curr_img = resize_ar(curr_img, 0, curr_row.shape[0])\n",
        "                curr_row = np.concatenate((curr_row, curr_img), axis=inner_axis)\n",
        "\n",
        "            curr_h, curr_w = curr_img.shape[:2]\n",
        "            stack_locations.append((start_row, start_col, start_row + curr_h, start_col + curr_w))\n",
        "            start_col += curr_w\n",
        "\n",
        "        if stacked_img is None:\n",
        "            stacked_img = curr_row\n",
        "        else:\n",
        "            if borderless:\n",
        "                resize_factor = float(curr_row.shape[1]) / float(stacked_img.shape[1])\n",
        "                if curr_row.shape[1] < stacked_img.shape[1]:\n",
        "                    curr_row = resize_ar(curr_row, stacked_img.shape[1], 0, placement_type=placement_type)\n",
        "                elif curr_row.shape[1] > stacked_img.shape[1]:\n",
        "                    stacked_img = resize_ar(stacked_img, curr_row.shape[1], 0)\n",
        "\n",
        "                new_start_col = 0\n",
        "                for _i in range(n_cols):\n",
        "                    _start_row, _start_col, _end_row, _end_col = stack_locations[_i - n_cols]\n",
        "                    _w, _h = _end_col - _start_col, _end_row - _start_row\n",
        "                    w_resized, h_resized = _w / resize_factor, _h / resize_factor\n",
        "                    stack_locations[_i - n_cols] = (\n",
        "                        _start_row, new_start_col, _start_row + h_resized, new_start_col + w_resized)\n",
        "                    new_start_col += w_resized\n",
        "            stacked_img = np.concatenate((stacked_img, curr_row), axis=stack_order)\n",
        "\n",
        "        curr_h, curr_w = curr_row.shape[:2]\n",
        "        start_row += curr_h\n",
        "\n",
        "        if list_ended:\n",
        "            break\n",
        "    if return_idx:\n",
        "        return stacked_img, stack_idx, stack_locations\n",
        "    else:\n",
        "        return stacked_img\n",
        "\n",
        "\n",
        "def vis_seg(src_img, gt_seg, img_id, class_cols, vis_size):\n",
        "    vis_img_seg_gt = np.zeros_like(src_img)\n",
        "\n",
        "    seg_img_gt = gt_seg[img_id, ...].squeeze().reshape((64, 64)).astype(np.uint8)\n",
        "\n",
        "    for cls, col in class_cols.items():\n",
        "        vis_img_seg_gt[seg_img_gt == cls] = col_bgr[col]\n",
        "\n",
        "    vis_img_seg_gt = resize_ar(vis_img_seg_gt, *vis_size)\n",
        "    return vis_img_seg_gt\n",
        "\n",
        "\n",
        "def annotate(img_list, text=None,\n",
        "             fmt=None,\n",
        "             grid_size=(-1, 1),\n",
        "             max_width=0, max_height=0,\n",
        "             img_labels=None,\n",
        "             width=0, height=0):\n",
        "    \"\"\"\n",
        "\n",
        "    :param np.ndarray | list | tuple img_list:\n",
        "    :param str text:\n",
        "    :param CVText fmt:\n",
        "    :param tuple(int) grid_size:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(img_list, (list, tuple)):\n",
        "        img_list = [img_list, ]\n",
        "\n",
        "    if width > 0 or height > 0:\n",
        "        for k, img in enumerate(img_list):\n",
        "            img_list[k] = resize_ar(img, width=width, height=height)\n",
        "\n",
        "    if img_labels is not None:\n",
        "        assert len(img_labels) == len(img_list), \"img_labels and img_list must have same length\"\n",
        "\n",
        "    if fmt is None:\n",
        "        \"\"\"use default format\"\"\"\n",
        "        fmt = CVText()\n",
        "\n",
        "    size = fmt.size\n",
        "\n",
        "    color = col_bgr[fmt.color]\n",
        "    font = CVConstants.fonts[fmt.font]\n",
        "    line_type = CVConstants.line_types[fmt.line_type]\n",
        "\n",
        "    out_img_list = []\n",
        "\n",
        "    for _id, _img in enumerate(img_list):\n",
        "        if len(_img.shape) == 2:\n",
        "            _img = np.stack([_img, ] * 3, axis=2)\n",
        "\n",
        "        if img_labels is not None:\n",
        "            img_label = img_labels[_id]\n",
        "            (text_width, text_height) = cv2.getTextSize(\n",
        "                img_label, font,\n",
        "                fontScale=fmt.size,\n",
        "                thickness=fmt.thickness)[0]\n",
        "\n",
        "            text_height += fmt.offset[1]\n",
        "            text_width += fmt.offset[0]\n",
        "            label_img = np.zeros((text_height, text_width), dtype=np.uint8)\n",
        "            cv2.putText(label_img, img_label, tuple(fmt.offset),\n",
        "                        font, size, color, fmt.thickness, line_type)\n",
        "\n",
        "            if len(_img.shape) == 3:\n",
        "                label_img = np.stack([label_img, ] * 3, axis=2)\n",
        "\n",
        "            if text_width < _img.shape[1]:\n",
        "                label_img = resize_ar(label_img, width=_img.shape[1], height=text_height,\n",
        "                                      only_border=2, placement_type=1)\n",
        "\n",
        "            border_img = np.full((5, _img.shape[0], 3), 255, dtype=np.uint8)\n",
        "\n",
        "            img_list_label = [label_img, border_img, _img]\n",
        "\n",
        "            _img = stack_images(img_list_label, grid_size=(-1, 1), preserve_order=1)\n",
        "\n",
        "        border_img = np.full((_img.shape[0], 5, 3), 255, dtype=np.uint8)\n",
        "        _img = stack_images([_img, border_img], grid_size=(1, -1), preserve_order=1)\n",
        "\n",
        "        out_img_list.append(_img)\n",
        "\n",
        "    img_stacked = stack_images(out_img_list, grid_size=grid_size, preserve_order=1)\n",
        "\n",
        "    if text is not None:\n",
        "        if '\\n' in text:\n",
        "            text_list = text.split('\\n')\n",
        "        else:\n",
        "            text_list = [text, ]\n",
        "\n",
        "        max_text_width = 0\n",
        "        text_height = 0\n",
        "        text_heights = []\n",
        "\n",
        "        for _text in text_list:\n",
        "            (_text_width, _text_height) = cv2.getTextSize(_text, font, fontScale=fmt.size, thickness=fmt.thickness)[0]\n",
        "            if _text_width > max_text_width:\n",
        "                max_text_width = _text_width\n",
        "            text_height += _text_height + 5\n",
        "            text_heights.append(_text_height)\n",
        "\n",
        "        text_width = max_text_width + 10\n",
        "        text_height += 30\n",
        "\n",
        "        text_img = np.zeros((text_height, text_width, 3), dtype=np.uint8)\n",
        "        location = list(fmt.offset)\n",
        "\n",
        "        for _id, _text in enumerate(text_list):\n",
        "            cv2.putText(text_img, _text, tuple(location), font, size, color, fmt.thickness, line_type)\n",
        "            location[1] += text_heights[_id] + 5\n",
        "\n",
        "        if text_width < img_stacked.shape[1]:\n",
        "            text_img = resize_ar(text_img, width=img_stacked.shape[1], height=text_height,\n",
        "                                 only_border=2, placement_type=1)\n",
        "\n",
        "        border_img = np.full((5, img_stacked.shape[1], 3), 255, dtype=np.uint8)\n",
        "\n",
        "        img_list_txt = [text_img, border_img, img_stacked]\n",
        "\n",
        "        img_stacked = stack_images(img_list_txt, grid_size=(-1, 1), preserve_order=1,\n",
        "                                   )\n",
        "    if img_stacked.shape[0] > max_height > 0:\n",
        "        img_stacked = resize_ar(img_stacked, height=max_height)\n",
        "\n",
        "    if img_stacked.shape[1] > max_width > 0:\n",
        "        img_stacked = resize_ar(img_stacked, width=max_width)\n",
        "\n",
        "    return img_stacked\n",
        "\n",
        "\n",
        "def vis_bboxes(img, bbox_1, bbox_2, y1, y2, vis_size):\n",
        "    import cv2\n",
        "\n",
        "    ymin, xmin, ymax, xmax = bbox_1\n",
        "\n",
        "    cv2.rectangle(img, (int(xmin), int(ymin)), (int(xmax), int(ymax)),\n",
        "                  (0, 255, 0), thickness=1)\n",
        "    cv2.putText(img, f'{int(y1):d}', (xmin, ymin), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                0.4, (0, 255, 0))\n",
        "\n",
        "    ymin, xmin, ymax, xmax = bbox_2\n",
        "    cv2.rectangle(img, (int(xmin), int(ymin)), (int(xmax), int(ymax)),\n",
        "                  (255, 0, 0), thickness=1)\n",
        "    cv2.putText(img, f'{int(y2):d}', (xmin, ymin), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "                0.4, (255, 0, 0))\n",
        "\n",
        "    img = resize_ar(img, *vis_size)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def get_size(width, height, src_height, src_width, src_aspect_ratio, only_shrink, only_border):\n",
        "    if width <= 0 and height <= 0:\n",
        "        raise AssertionError('Both width and height cannot be zero')\n",
        "    elif height <= 0:\n",
        "        if only_shrink and width > src_width:\n",
        "            width = src_width\n",
        "        if only_border == 1:\n",
        "            height = src_height\n",
        "        # elif only_border == 2:\n",
        "        #     pass\n",
        "        else:\n",
        "            height = int(width / src_aspect_ratio)\n",
        "    elif width <= 0:\n",
        "        if only_shrink and height > src_height:\n",
        "            height = src_height\n",
        "\n",
        "        if only_border == 1:\n",
        "            width = src_width\n",
        "        # elif only_border == 2:\n",
        "        #     pass\n",
        "        else:\n",
        "            width = int(height * src_aspect_ratio)\n",
        "\n",
        "    return width, height\n",
        "\n",
        "\n",
        "def resize_ar(src_img, width=0, height=0, return_factors=False,\n",
        "              placement_type=1, only_border=0,\n",
        "              only_shrink=0, resize_factor=None,\n",
        "              size=None, auto_max=1):\n",
        "    if size is not None:\n",
        "        width, height = size\n",
        "\n",
        "    src_height, src_width = src_img.shape[:2]\n",
        "\n",
        "    if resize_factor is not None:\n",
        "        width, height = int(src_width * resize_factor), int(src_height * resize_factor)\n",
        "\n",
        "    src_aspect_ratio = float(src_width) / float(src_height)\n",
        "\n",
        "    if len(src_img.shape) == 3:\n",
        "        n_channels = src_img.shape[2]\n",
        "    else:\n",
        "        n_channels = 1\n",
        "\n",
        "    if only_border == 2:\n",
        "        assert width > 0 and height > 0, \\\n",
        "            \"both width and height must be provided for strict only_border mode\"\n",
        "        assert src_width <= width and src_height <= height, \\\n",
        "            \"source size must be <= target size for strict only_border mode\"\n",
        "    else:\n",
        "        if auto_max and width > 0 and height > 0:\n",
        "            width1, height1 = get_size(width, 0, src_height, src_width, src_aspect_ratio, only_shrink, only_border)\n",
        "            width2, height2 = get_size(0, height, src_height, src_width, src_aspect_ratio, only_shrink, only_border)\n",
        "\n",
        "            height_diff = height1 - height\n",
        "            width_diff = width2 - width\n",
        "\n",
        "            if height_diff > width_diff:\n",
        "                width, height = width2, height2\n",
        "            else:\n",
        "                width, height = width1, height1\n",
        "        else:\n",
        "            width, height = get_size(width, height,\n",
        "                                     src_height, src_width,\n",
        "                                     src_aspect_ratio,\n",
        "                                     only_shrink, only_border)\n",
        "\n",
        "    aspect_ratio = float(width) / float(height)\n",
        "\n",
        "    if only_border:\n",
        "        dst_width = width\n",
        "        dst_height = height\n",
        "        if placement_type == 0:\n",
        "            start_row = start_col = 0\n",
        "        elif placement_type == 1:\n",
        "            start_row = int((dst_height - src_height) / 2.0)\n",
        "            start_col = int((dst_width - src_width) / 2.0)\n",
        "        elif placement_type == 2:\n",
        "            start_row = int(dst_height - src_height)\n",
        "            start_col = int(dst_width - src_width)\n",
        "        else:\n",
        "            raise AssertionError('Invalid placement_type: {}'.format(placement_type))\n",
        "    else:\n",
        "        if src_aspect_ratio == aspect_ratio:\n",
        "            dst_width = src_width\n",
        "            dst_height = src_height\n",
        "            start_row = start_col = 0\n",
        "        elif src_aspect_ratio > aspect_ratio:\n",
        "            dst_width = src_width\n",
        "            dst_height = int(src_width / aspect_ratio)\n",
        "            start_row = int((dst_height - src_height) / 2.0)\n",
        "            if placement_type == 0:\n",
        "                start_row = 0\n",
        "            elif placement_type == 1:\n",
        "                start_row = int((dst_height - src_height) / 2.0)\n",
        "            elif placement_type == 2:\n",
        "                start_row = int(dst_height - src_height)\n",
        "            else:\n",
        "                raise AssertionError('Invalid placement_type: {}'.format(placement_type))\n",
        "            start_col = 0\n",
        "        else:\n",
        "            dst_height = src_height\n",
        "            dst_width = int(src_height * aspect_ratio)\n",
        "            start_col = int((dst_width - src_width) / 2.0)\n",
        "            if placement_type == 0:\n",
        "                start_col = 0\n",
        "            elif placement_type == 1:\n",
        "                start_col = int((dst_width - src_width) / 2.0)\n",
        "            elif placement_type == 2:\n",
        "                start_col = int(dst_width - src_width)\n",
        "            else:\n",
        "                raise AssertionError('Invalid placement_type: {}'.format(placement_type))\n",
        "            start_row = 0\n",
        "\n",
        "    dst_img = np.zeros((dst_height, dst_width, n_channels), dtype=src_img.dtype)\n",
        "    dst_img = dst_img.squeeze()\n",
        "\n",
        "    dst_img[start_row:start_row + src_height, start_col:start_col + src_width, ...] = src_img\n",
        "    if not only_border:\n",
        "        dst_img = cv2.resize(dst_img, (width, height))\n",
        "\n",
        "    if return_factors:\n",
        "        resize_factor = float(height) / float(dst_height)\n",
        "        return dst_img, resize_factor, start_row, start_col\n",
        "    else:\n",
        "        return dst_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LO3HrqGda-iF"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "from skimage.draw import polygon\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rj2L_9KWbCnw"
      },
      "outputs": [],
      "source": [
        "def compute_classification_acc(pred, gt):\n",
        "    assert pred.shape == gt.shape\n",
        "    return (pred == gt).astype(int).sum() / gt.size\n",
        "\n",
        "\n",
        "def compute_segmentation_acc(pred, gt):\n",
        "    # pred value should be from 0 to 10, where 10 is the background.\n",
        "    assert pred.shape == gt.shape\n",
        "\n",
        "    return (pred == gt).astype(int).sum() / gt.size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ydfZxk0ubN8N"
      },
      "outputs": [],
      "source": [
        "def get_iou(bbox_pred, bbox_gt, L_pred, L_gt):\n",
        "    \"\"\"all pixel coordinates within the prediction bounding box\"\"\"\n",
        "    rr, cc = polygon([bbox_pred[0], bbox_pred[0], bbox_pred[2], bbox_pred[2]],\n",
        "                     [bbox_pred[1], bbox_pred[3], bbox_pred[3], bbox_pred[1]], [64, 64])\n",
        "    L_pred[rr, cc] = 1\n",
        "\n",
        "    \"\"\"all pixel coordinates within the GT bounding box\"\"\"\n",
        "    rr, cc = polygon([bbox_gt[0], bbox_gt[0], bbox_gt[2], bbox_gt[2]],\n",
        "                     [bbox_gt[1], bbox_gt[3], bbox_gt[3], bbox_gt[1]], [64, 64])\n",
        "    L_gt[rr, cc] = 1\n",
        "\n",
        "    L_sum = L_pred + L_gt\n",
        "    intersection = np.sum(L_sum == 2)\n",
        "    union = np.sum(L_sum >= 1)\n",
        "\n",
        "    iou = intersection / union\n",
        "\n",
        "    L_pred[:, :] = 0\n",
        "    L_gt[:, :] = 0\n",
        "\n",
        "    return iou\n",
        "\n",
        "\n",
        "def compute_mean_iou(bboxes_pred, bboxes_gt, classes_pred, classes_gt):\n",
        "    \"\"\"\n",
        "\n",
        "    :param bboxes_pred: predicted bounding boxes, shape=(n_images,2,4)\n",
        "    :param bboxes_gt: ground truth bounding boxes, shape=(n_images,2,4)\n",
        "    :param classes_pred: predicted classes, shape=(n_images,2)\n",
        "    :param classes_gt: ground truth classes, shape=(n_images,2)\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    n_images = np.shape(bboxes_gt)[0]\n",
        "    L_pred = np.zeros((64, 64))\n",
        "    L_gt = np.zeros((64, 64))\n",
        "    iou_sum = 0.0\n",
        "    for i in range(n_images):\n",
        "        iou1 = get_iou(bboxes_pred[i, 0, :], bboxes_gt[i, 0, :], L_pred, L_gt)\n",
        "        iou2 = get_iou(bboxes_pred[i, 1, :], bboxes_gt[i, 1, :], L_pred, L_gt)\n",
        "\n",
        "        iou_sum1 = iou1 + iou2\n",
        "\n",
        "        if classes_pred[i, 0] == classes_pred[i, 1] and classes_gt[i, 0] == classes_gt[i, 1]:\n",
        "            iou1 = get_iou(bboxes_pred[i, 0, :], bboxes_gt[i, 1, :], L_pred, L_gt)\n",
        "            iou2 = get_iou(bboxes_pred[i, 1, :], bboxes_gt[i, 0, :], L_pred, L_gt)\n",
        "\n",
        "            iou_sum2 = iou1 + iou2\n",
        "\n",
        "            if iou_sum2 > iou_sum1:\n",
        "                iou_sum1 = iou_sum2\n",
        "\n",
        "        iou_sum += iou_sum1\n",
        "\n",
        "    mean_iou = iou_sum / (2. * n_images)\n",
        "\n",
        "    return mean_iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL0ds08MbbYO",
        "outputId": "76926030-55cd-4dd7-ecbb-0b55560b1843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid\n",
            "['.config', '.ipynb_checkpoints', 'gdrive', 'sample_data']\n",
            "running prediction on 5000 valid images\n",
            "['.config', '.ipynb_checkpoints', 'gdrive', 'sample_data']\n",
            "cuda\n",
            "Classification Accuracy: 98.050 %\n",
            "Detection IOU: 92.538 %\n",
            "Segmentation Accuracy: 99.669 %\n",
            "Test time: 74.939 seconds\n",
            "Test speed: 66.721 images / second\n",
            "Classification Score: 100.000\n",
            "IOU Score: 80.494\n",
            "Segmentation Score: 100.000\n",
            "Overall Score: 95.124\n"
          ]
        }
      ],
      "source": [
        "class Params:\n",
        "    def __init__(self):\n",
        "        # self.prefix = \"test\"\n",
        "        self.prefix = \"valid\"\n",
        "        # self.prefix = \"train\"\n",
        "        self.load = 1\n",
        "        self.save = 1\n",
        "        self.load_path = 'saved_preds.npz'\n",
        "        self.vis = 0\n",
        "        self.vis_size = (300, 300)\n",
        "        self.show_det = 0\n",
        "        self.show_seg = 1\n",
        "\n",
        "        self.speed_thresh = 10\n",
        "        self.acc_thresh = (0.7, 0.98)\n",
        "        self.iou_thresh = (0.7, 0.98)\n",
        "        self.seg_thresh = (0.7, 0.98)\n",
        "\n",
        "        self.class_cols = {\n",
        "            0: 'red',\n",
        "            1: 'green',\n",
        "            2: 'blue',\n",
        "            3: 'magenta',\n",
        "            4: 'cyan',\n",
        "            5: 'yellow',\n",
        "            6: 'purple',\n",
        "            7: 'forest_green',\n",
        "            8: 'orange',\n",
        "            9: 'white',\n",
        "            10: 'black',\n",
        "        }\n",
        "\n",
        "\n",
        "def compute_score(res, thresh):\n",
        "    min_thres, max_thres = thresh\n",
        "\n",
        "    if res < min_thres:\n",
        "        score = 0.0\n",
        "    elif res > max_thres:\n",
        "        score = 100.0\n",
        "    else:\n",
        "        score = float(res - min_thres) / (max_thres - min_thres) * 100\n",
        "    return score\n",
        "\n",
        "def draw_bboxes(img, bbox_1, bbox_2, y1, y2, vis_size):\n",
        "    import cv2\n",
        "\n",
        "    ymin, xmin, ymax, xmax = bbox_1\n",
        "\n",
        "    cv2.rectangle(img, (int(xmin), int(ymin)), (int(\n",
        "        xmax), int(ymax)), (0, 255, 0), thickness=1)\n",
        "    cv2.putText(img, '{:d}'.format(y1), (xmin, ymin),\n",
        "                cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.4, (0, 255, 0))\n",
        "\n",
        "    ymin, xmin, ymax, xmax = bbox_2\n",
        "    cv2.rectangle(img, (int(xmin), int(ymin)), (int(\n",
        "        xmax), int(ymax)), (255, 0, 0), thickness=1)\n",
        "    cv2.putText(img, '{:d}'.format(y2), (xmin, ymin),\n",
        "                cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.4, (255, 0, 0))\n",
        "\n",
        "    img = resize_ar(img, *vis_size)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def main():\n",
        "    params = Params()\n",
        "\n",
        "    try:\n",
        "        import paramparse\n",
        "    except ImportError:\n",
        "        pass\n",
        "    else:\n",
        "        paramparse.process(params)\n",
        "\n",
        "    prefix = params.prefix\n",
        "    print(prefix)\n",
        "    print(os.listdir())\n",
        "    images = np.load(\"/content/gdrive/MyDrive/Colab Notebooks/ASS4/\" +prefix + \"_X.npy\")\n",
        "    gt_classes = np.load(\"/content/gdrive/MyDrive/Colab Notebooks/ASS4/\" +prefix + \"_Y.npy\")\n",
        "    gt_bboxes = np.load(\"/content/gdrive/MyDrive/Colab Notebooks/ASS4/\" +prefix + \"_bboxes.npy\")\n",
        "    gt_seg = np.load(\"/content/gdrive/MyDrive/Colab Notebooks/ASS4/\" +prefix + \"_seg.npy\")\n",
        "\n",
        "    n_images = images.shape[0]\n",
        "\n",
        "\n",
        "    if params.load and os.path.exists(params.load_path):\n",
        "        print(f'loading predictions from {params.load_path}')\n",
        "        saved_preds = np.load(params.load_path)\n",
        "        pred_classes = saved_preds['pred_classes']\n",
        "        pred_bboxes = saved_preds['pred_bboxes']\n",
        "        pred_seg = saved_preds['pred_seg']\n",
        "\n",
        "        test_time = test_speed = 0\n",
        "    else:\n",
        "        print(f'running prediction on {n_images} {prefix} images')\n",
        "        start_t = timeit.default_timer()\n",
        "        pred_classes, pred_bboxes, pred_seg = detect_and_segment(images)\n",
        "        end_t = timeit.default_timer()\n",
        "        test_time = end_t - start_t\n",
        "        assert test_time > 0, \"test_time cannot be 0\"\n",
        "        test_speed = float(n_images) / test_time\n",
        "\n",
        "        if params.save:\n",
        "            np.savez_compressed(params.load_path, pred_classes=pred_classes, pred_bboxes=pred_bboxes, pred_seg=pred_seg)\n",
        "\n",
        "    cls_acc = compute_classification_acc(pred_classes, gt_classes)\n",
        "    iou = compute_mean_iou(pred_bboxes, gt_bboxes, pred_classes, gt_classes)\n",
        "    seg_acc = compute_segmentation_acc(pred_seg, gt_seg)\n",
        "\n",
        "    acc_score = compute_score(cls_acc, params.acc_thresh)\n",
        "    iou_score = compute_score(iou, params.iou_thresh)\n",
        "    seg_score = compute_score(seg_acc, params.seg_thresh)\n",
        "\n",
        "    if test_speed < params.speed_thresh:\n",
        "        overall_score = 0\n",
        "    else:\n",
        "        overall_score = ((iou_score + acc_score) / 2. + seg_score) / 2.\n",
        "\n",
        "    print(f\"Classification Accuracy: {cls_acc*100:.3f} %\")\n",
        "    print(f\"Detection IOU: {iou*100:.3f} %\")\n",
        "    print(f\"Segmentation Accuracy: {seg_acc*100:.3f} %\")\n",
        "\n",
        "    print(f\"Test time: {test_time:.3f} seconds\")\n",
        "    print(f\"Test speed: {test_speed:.3f} images / second\")\n",
        "\n",
        "    print(f\"Classification Score: {acc_score:.3f}\")\n",
        "    print(f\"IOU Score: {iou_score:.3f}\")\n",
        "    print(f\"Segmentation Score: {seg_score:.3f}\")\n",
        "    print(f\"Overall Score: {overall_score:.3f}\")\n",
        "\n",
        "    if not params.vis:\n",
        "        return\n",
        "\n",
        "    import cv2\n",
        "    # from A4_utils import vis_bboxes, vis_seg, annotate\n",
        "\n",
        "    print('press spacebar to toggle pause and escape to quit')\n",
        "    pause_after_frame = 1\n",
        "    for img_id in range(n_images):\n",
        "        src_img = images[img_id, ...].squeeze()\n",
        "        src_img = src_img.reshape((64, 64, 3)).astype(np.uint8)\n",
        "\n",
        "        vis_img = np.copy(src_img)\n",
        "\n",
        "        bbox_1 = gt_bboxes[img_id, 0, :].squeeze().astype(np.int32)\n",
        "        bbox_2 = gt_bboxes[img_id, 1, :].squeeze().astype(np.int32)\n",
        "        y1, y2 = gt_classes[img_id, ...].squeeze()\n",
        "        gt_classes[img_id, ...].squeeze()\n",
        "        vis_img = vis_bboxes(vis_img, bbox_1, bbox_2, y1, y2, params.vis_size)\n",
        "        vis_img_seg_gt = vis_seg(src_img, gt_seg, img_id, params.class_cols, params.vis_size)\n",
        "\n",
        "        vis_img_list = [vis_img, vis_img_seg_gt]\n",
        "        vis_img_labels = ['gt det', 'gt seg']\n",
        "\n",
        "        if params.show_det:\n",
        "            vis_img_det = np.copy(src_img)\n",
        "            bbox_1 = pred_bboxes[img_id, 0, :].squeeze().astype(np.int32)\n",
        "            bbox_2 = pred_bboxes[img_id, 1, :].squeeze().astype(np.int32)\n",
        "            y1, y2 = pred_classes[img_id, ...].squeeze()\n",
        "            gt_classes[img_id, ...].squeeze()\n",
        "            vis_img_det = vis_bboxes(vis_img_det, bbox_1, bbox_2, y1, y2, params.vis_size)\n",
        "            vis_img_list.append(vis_img_det)\n",
        "            vis_img_labels.append('pred det')\n",
        "\n",
        "        if params.show_seg:\n",
        "            vis_img_seg = vis_seg(src_img, pred_seg, img_id, params.class_cols, params.vis_size)\n",
        "            vis_img_list.append(vis_img_seg)\n",
        "            vis_img_labels.append('pred seg')\n",
        "\n",
        "        vis_img = annotate(vis_img_list,\n",
        "                           text=f'image {img_id}',\n",
        "                           img_labels=vis_img_labels, grid_size=(1, -1))\n",
        "        cv2.imshow('vis_img', vis_img)\n",
        "\n",
        "        key = cv2.waitKey(1 - pause_after_frame)\n",
        "        if key == 27:\n",
        "            return\n",
        "        elif key == 32:\n",
        "            pause_after_frame = 1 - pause_after_frame\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MmxlWtMZYwi"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
